# transformer-network

- 1. word embedding concept
- 2. one-hot word embedding
- 3. inner product
- 4. relative similarity concept
- 5. 

# 1. Introduction to word embedding concept

The idea is every word in our vocabualry is gonna be mapped to a vector!

<img src="./img/w2vec.png">
A firly novel way to get a depper understanging out of it is to imagine a world map. 

<img src="./img/world.png">